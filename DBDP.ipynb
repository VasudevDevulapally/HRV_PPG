{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrv(file, complete_sequence=\"false\", threshold=0.1, x=50, correction=\"false\", fs=4):\n",
    "\n",
    "    '''(file, complete_sequence=\"false\", threshold=0.1,  x=50, correction=\"false\") -> {HRV Metrics}\n",
    "\n",
    "    Returns a dictionary of time and frequency domain metricspiazza\n",
    "\n",
    "\n",
    "    file - is the data file with the first column as time, and the second column as IBI\n",
    "\n",
    "    complete_sequence - takes a true or false argument for whether you require the longest sequence of non missing data\n",
    "\n",
    "    threshold - is used to set the permissible difference between IBI\n",
    "\n",
    "    x - is the time in milliseconds for calculating pNN and NN\n",
    "\n",
    "    correction - is to take care of outliers, should be used carefully\n",
    "\n",
    "    fs - for sample rate interpolation in frequency domain\n",
    "\n",
    "\n",
    "    example:\n",
    "\n",
    "    >>> h = hrv(\"ibi.csv\")\n",
    "\n",
    "\n",
    "    {'MeanRR': 1033.9,\n",
    "\n",
    "     'MeanHR': 58.6,\n",
    "\n",
    "     'MinHR': 48.1,\n",
    "\n",
    "     'MaxHR': 89.5,\n",
    "\n",
    "     'SDNN': 103.1,\n",
    "\n",
    "     'RMSSD': 70.9,\n",
    "\n",
    "     'NNx': 2257.0,\n",
    "\n",
    "     'pNNx': 38.7,\n",
    "\n",
    "     'PowerVLF': 1828.85,\n",
    "\n",
    "     'PowerLF': 1852.32,\n",
    "\n",
    "     'PowerHF': 1299.42,\n",
    "\n",
    "     'PowerTotal': 4980.6,\n",
    "\n",
    "     'LF/HF': 1.43,\n",
    "\n",
    "     'PeakVLF': 0.02,\n",
    "\n",
    "     'PeakLF': 0.05,\n",
    "\n",
    "     'PeakHF': 0.27,\n",
    "\n",
    "     'FractionLF': 58.77,\n",
    "\n",
    "     'FractionHF': 41.23}\n",
    "\n",
    "    '''\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    from scipy.stats import zscore\n",
    "\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    from scipy import signal\n",
    "\n",
    "    from scipy.integrate import trapz\n",
    "\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    # Function for reading csv file and extracting timer and ibi\n",
    "\n",
    "    def readTimerIBI(file, complete_sequence, threshold):\n",
    "\n",
    "        '''(file_location, complete_sequence=\"false\",threshold=0.1) -> {time_domain dictionary}\n",
    "\n",
    "        Returns file in the required format.\n",
    "\n",
    "\n",
    "        file_location is the data file with the first column as time, and the second column as IBI\n",
    "\n",
    "        complete_sequence takes a true or false argument for whether you require the longest sequence of non missing data\n",
    "\n",
    "        threshold is used to set the permissible difference between IBI\n",
    "\n",
    "        '''\n",
    "\n",
    "        file = pd.read_csv(file)\n",
    "\n",
    "        file.columns = ['time', 'IBI']\n",
    "\n",
    "\n",
    "\n",
    "        if complete_sequence == \"false\":\n",
    "\n",
    "            # ibi = file['IBI']\n",
    "\n",
    "            # timer = file['time']\n",
    "\n",
    "            # timerIBI  = {\"ibi\": ibi, \"timer\": timer}\n",
    "\n",
    "            # return timerIBI\n",
    "\n",
    "            return file\n",
    "\n",
    "        else:\n",
    "\n",
    "            start = [file['time'][0]]\n",
    "\n",
    "            end = []\n",
    "\n",
    "            for i in range(1, len(file['time'] + 1)):\n",
    "\n",
    "                if abs(file['time'][i] - file['time'][i - 1] - file['IBI'][i]) > threshold:\n",
    "\n",
    "                    end.append(file['time'][i - 1])\n",
    "\n",
    "                    start.append(file['time'][i])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    continue\n",
    "\n",
    "            end.append(file['time'][len(file) - 1])\n",
    "\n",
    "\n",
    "\n",
    "            # get max data sequence\n",
    "\n",
    "            time_diff = list(np.array(end) - np.array(start))\n",
    "\n",
    "            index = [0]\n",
    "\n",
    "            max_cut_off = 0\n",
    "\n",
    "            for i in time_diff:\n",
    "\n",
    "                if i >= max_cut_off:\n",
    "\n",
    "                    max_cut_off = i\n",
    "\n",
    "                    index[0] = time_diff.index(i)\n",
    "\n",
    "            s = []\n",
    "\n",
    "            e = []\n",
    "\n",
    "            d = []\n",
    "\n",
    "            for i in index:\n",
    "\n",
    "                s.append(start[i])\n",
    "\n",
    "                e.append(end[i])\n",
    "\n",
    "                d.append(end[i] - start[i])\n",
    "\n",
    "            data = {'start': s, 'end': e, 'difference': d}\n",
    "\n",
    "\n",
    "\n",
    "            df = file.loc[(file['time'] >= data['start']) & (file['time'] <= data['end'])]\n",
    "\n",
    "\n",
    "\n",
    "            return (df)\n",
    "\n",
    "\n",
    "\n",
    "    # Function for calculating Time domain\n",
    "\n",
    "    # Takes two parameters: timerIBI, an optional x for NN calculations, and correction, if outliers should be corrected for\n",
    "\n",
    "    def timeDomain(timerIBI, x, correction):\n",
    "\n",
    "        ''' (readTimerIBI object, x=50, correction=\"false\") -> Time Domain Dictionary\n",
    "\n",
    "\n",
    "        Returns a time domain dictionary of readTimerIBI object\n",
    "\n",
    "\n",
    "        x is the time in milliseconds for calculating pNN and NN\n",
    "\n",
    "        correction is to take care of outliers, should be used carefully\n",
    "\n",
    "        '''\n",
    "\n",
    "        t = timerIBI['time']\n",
    "\n",
    "        ibi2 = timerIBI['IBI'] * 1000  # converts seconds to ms\n",
    "\n",
    "        ibi = ibi2.rolling(window=10).mean()[10:]\n",
    "\n",
    "\n",
    "\n",
    "        if correction == \"true\":\n",
    "\n",
    "            ibi_set = ibi.copy()\n",
    "\n",
    "            ibi[np.abs(zscore(ibi_set)) > 2] = np.median(ibi_set)\n",
    "\n",
    "\n",
    "\n",
    "        def pNNX(ibi, x):\n",
    "\n",
    "            differences = abs(np.diff(ibi))\n",
    "\n",
    "            n = np.sum(differences > x)\n",
    "\n",
    "            p = (n / len(differences)) * 100\n",
    "\n",
    "            return (p, n)\n",
    "\n",
    "\n",
    "\n",
    "        def RMSSD(ibi):\n",
    "\n",
    "            differences = abs(np.diff(ibi))\n",
    "\n",
    "            rmssd = np.sqrt(np.sum(np.square(differences)) / len(differences))\n",
    "\n",
    "            return rmssd\n",
    "\n",
    "\n",
    "\n",
    "        maxHrv = round(max(ibi) * 10) / 10\n",
    "\n",
    "        minHrv = round(min(ibi) * 10) / 10\n",
    "\n",
    "        meanHrv = round(np.mean(ibi) * 10) / 10\n",
    "\n",
    "        medianHrv = round(np.median(ibi) * 10) / 10\n",
    "\n",
    "        sdnn = round(np.std(ibi) * 10) / 10\n",
    "\n",
    "        p, n = pNNX(ibi2, x)\n",
    "\n",
    "        nnx = round(n * 10) / 10\n",
    "\n",
    "        pnnx = round(p * 10) / 10\n",
    "\n",
    "        rmssd = round(RMSSD(ibi2) * 10) / 10\n",
    "\n",
    "        hr = 60 / (ibi / 1000)\n",
    "\n",
    "        meanHR = round(np.mean(hr) * 10) / 10\n",
    "\n",
    "        maxHR = round(np.max(hr) * 10) / 10\n",
    "\n",
    "        minHR = round(np.min(hr) * 10) / 10\n",
    "\n",
    "        time_domain = {\"MeanRR\": meanHrv, \"MeanHR\": meanHR,\n",
    "\n",
    "                       \"MinHR\": minHR, \"MaxHR\": maxHR,\n",
    "\n",
    "                       \"SDNN\": sdnn, \"RMSSD\": rmssd, \"NNx\": nnx,\n",
    "\n",
    "                       \"pNNx\": pnnx}\n",
    "\n",
    "\n",
    "\n",
    "        return time_domain\n",
    "\n",
    "\n",
    "\n",
    "    # Function for calculating Frequency domain\n",
    "\n",
    "    # Takes two parameters: timerIBI, an optional fs for frequency interpolation\n",
    "\n",
    "    def frequencyDomain(timerIBI, fs):\n",
    "\n",
    "\n",
    "\n",
    "        ibi = timerIBI['IBI'] * 1000\n",
    "\n",
    "        steps = 1 / fs\n",
    "\n",
    "\n",
    "\n",
    "        # create interpolation function based on the rr-samples.\n",
    "\n",
    "        x = np.cumsum(ibi) / 1000.0\n",
    "\n",
    "        f = interp1d(x, ibi, kind='cubic')\n",
    "\n",
    "\n",
    "\n",
    "        # now we can sample from interpolation function\n",
    "\n",
    "        xx = np.arange(1, np.max(x), steps)\n",
    "\n",
    "        ibi_interpolated = f(xx)\n",
    "\n",
    "\n",
    "\n",
    "        # second part\n",
    "\n",
    "        fxx, pxx = signal.welch(x=ibi_interpolated, fs=fs)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        Segement found frequencies in the bands \n",
    "\n",
    "         - Very Low Frequency (VLF): 0-0.04Hz \n",
    "\n",
    "         - Low Frequency (LF): 0.04-0.15Hz \n",
    "\n",
    "         - High Frequency (HF): 0.15-0.4Hz\n",
    "\n",
    "        '''\n",
    "\n",
    "        cond_vlf = (fxx >= 0) & (fxx < 0.04)\n",
    "\n",
    "        cond_lf = (fxx >= 0.04) & (fxx < 0.15)\n",
    "\n",
    "        cond_hf = (fxx >= 0.15) & (fxx < 0.4)\n",
    "\n",
    "\n",
    "\n",
    "        # calculate power in each band by integrating the spectral density\n",
    "\n",
    "        vlf = trapz(pxx[cond_vlf], fxx[cond_vlf])\n",
    "\n",
    "        lf = trapz(pxx[cond_lf], fxx[cond_lf])\n",
    "\n",
    "        hf = trapz(pxx[cond_hf], fxx[cond_hf])\n",
    "\n",
    "\n",
    "\n",
    "        # sum these up to get total power\n",
    "\n",
    "        total_power = vlf + lf + hf\n",
    "\n",
    "\n",
    "\n",
    "        # find which frequency has the most power in each band\n",
    "\n",
    "        peak_vlf = fxx[cond_vlf][np.argmax(pxx[cond_vlf])]\n",
    "\n",
    "        peak_lf = fxx[cond_lf][np.argmax(pxx[cond_lf])]\n",
    "\n",
    "        peak_hf = fxx[cond_hf][np.argmax(pxx[cond_hf])]\n",
    "\n",
    "\n",
    "\n",
    "        # fraction of lf and hf\n",
    "\n",
    "        lf_nu = 100 * lf / (lf + hf)\n",
    "\n",
    "        hf_nu = 100 * hf / (lf + hf)\n",
    "\n",
    "\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        results['PowerVLF'] = round(vlf, 2)\n",
    "\n",
    "        results['PowerLF'] = round(lf, 2)\n",
    "\n",
    "        results['PowerHF'] = round(hf, 2)\n",
    "\n",
    "        results['PowerTotal'] = round(total_power, 2)\n",
    "\n",
    "        results['LF/HF'] = round(lf / hf, 2)\n",
    "\n",
    "        results['PeakVLF'] = round(peak_vlf, 2)\n",
    "\n",
    "        results['PeakLF'] = round(peak_lf, 2)\n",
    "\n",
    "        results['PeakHF'] = round(peak_hf, 2)\n",
    "\n",
    "        results['FractionLF'] = round(lf_nu, 2)\n",
    "\n",
    "        results['FractionHF'] = round(hf_nu, 2)\n",
    "\n",
    "\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "    data = readTimerIBI(file, complete_sequence, threshold)\n",
    "\n",
    "    td = timeDomain(data, x, correction)\n",
    "\n",
    "    fd = frequencyDomain(data, fs)\n",
    "\n",
    "\n",
    "\n",
    "    for k, v in td.items():\n",
    "\n",
    "        metrics[k] = v\n",
    "\n",
    "    for k, v in fd.items():\n",
    "\n",
    "        metrics[k] = v\n",
    "\n",
    "\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devtools = rpackages.importr('devtools')\n",
    "\n",
    "robjects.r('''\n",
    "#library(\"devtools\", lib.loc=\"C:/Program Files/R/R-3.5.2/library\")\n",
    "library(\"parallel\", lib.loc=\"C:/Program Files/R/R-3.5.2/library\")\n",
    "library(\"fasttime\", lib.loc=\"C:/Program Files/R/R-3.5.2/library\")\n",
    "require(data.table)\n",
    "require(plyr)\n",
    "require(psych)\n",
    "require(zoo)\n",
    "\n",
    "#assignInNamespace(\"version_info\", c(devtools:::version_info, list(\"3.5\" = list(version_min = \"3.3.0\", version_max = \"99.99.99\", path = \"bin\"))), \"devtools\")\n",
    "# #find_rtools()\n",
    "# #devtools::install_github('r-dbi/RSQLite')\n",
    "# library(RSQLite)\n",
    "# \n",
    "# filename <- \"wearables_clinical_deID.db\"\n",
    "# sqlite.driver <- dbDriver(\"SQLite\")\n",
    "# db <- dbConnect(sqlite.driver,\n",
    "#                 dbname = filename)\n",
    "# \n",
    "# ## default to_remove function\n",
    "# rem <- c(\"5d1a706641a0b458da136a16b6c65d6b\",\"c7c2d5fe4b4b981165a14f0684b31dae\",\n",
    "#          \"8ce925a402a0b3e31883d3c600ede9cd\",\"807a78004456272761454351a6a759ff\")\n",
    "# \n",
    "# #############\n",
    "# \n",
    "# #Table Data Loader\n",
    "# readDB <- function(tableName, columnString='*', where = '1 = 1'){\n",
    "#   table<- dbGetQuery(db, paste('select ',columnString, 'from ', tableName, ' where ', where))\n",
    "#   return(as.data.table(table))\n",
    "# }\n",
    "# \n",
    "# as.data.dataframe(table)\n",
    "\n",
    "readCSV <- function(fileName){\n",
    "  table<- read.csv(fileName)\n",
    "  return (as.data.frame(table))\n",
    "}\n",
    "\n",
    "#Is the data in the format IBI? If yes, change flag to TRUE:\n",
    "is_IBI = FALSE\n",
    "\n",
    "#Input .csv file here:\n",
    "\n",
    "Input_df = readCSV('Final_Test_HR_DBDP.csv')\n",
    "TB = Input_df[c(\"iPOP_ID\", \"Timestamp_Local\", \"Heart_Rate\", \"Steps\")]\n",
    "\n",
    "if(is_IBI){\n",
    "  TB = Input_df[c(\"Wearable_Account_MD5\", \"Timestamp_Local\", \"IBI\", \"Steps\")]\n",
    "}\n",
    "\n",
    "#If data starts in HR and want IBI, divide by 60 to get average IBI per minute:\n",
    "if (is_IBI){\n",
    "  TB = TB %>%\n",
    "    mutate(IBI = (1/Heart_Rate) * 60)\n",
    "    colnames(TB)[3] <- \"IBI\"\n",
    "}\n",
    "\n",
    "#Assign column names:\n",
    "colnames(TB)[1] <- \"Wearable_Account_MD5\"\n",
    "colnames(TB)[2] <- \"Timestamp_Local\"\n",
    "colnames(TB)[3] <- \"Heart_Rate\"\n",
    "colnames(TB)[4] <- \"Steps\"\n",
    "\n",
    "\n",
    "#########\n",
    "# #pulled up here for function construction. To be deleted\n",
    "# TB = readDB(\"wearable_data\")\n",
    "# demographics = readDB(\"demographics\")\n",
    "# lab_results = readDB(\"lab_results\")\n",
    "# vitals = readDB(\"vitals\")\n",
    "# TB = TB[1:100000,]\n",
    "# TB\n",
    "\n",
    "##########\n",
    "#Table Cleaner ## optional\n",
    "# cleanTable<-function(table, remm, colName){\n",
    "#   table2<<-table[! (eval(colName)) %in% remm]\n",
    "#   return(table2)\n",
    "# }\n",
    "# cleanTable(TB, '03de0e762b942438d6d7d8ba0ca0f929', quote(Wearable_Account_MD5))\n",
    "######################\n",
    "\n",
    "######################\n",
    "#a function that automates parallel computing\n",
    "parallelize<- function(data, func){\n",
    "  no_cores <-  detectCores()-1\n",
    "  cl <- makeCluster(no_cores)\n",
    "  newData <- parLapply(cl, data, func)\n",
    "  stopCluster(cl)\n",
    "  return(newData)\n",
    "}\n",
    "\n",
    "######################\n",
    "#change time format\n",
    "formatTime<-function(table, format_DIY, colName){\n",
    "  table$Date <- fastPOSIXct(table[,eval(colName)])\n",
    "  return (table)\n",
    "}\n",
    "TB <- formatTime(TB,\"%Y-%m-%d %H:%M:%S\", quote(Timestamp_Local))\n",
    "\n",
    "sapply(TB, class)\n",
    "\n",
    "########\n",
    "#columnInfoGetter\n",
    "getColumnInfo<- function(table, colName){\n",
    "  return(data.table(describe(table[,eval(colName)])))\n",
    "  \n",
    "}\n",
    "\n",
    "#SQL version of calling Daytime data (between 8am - 8pm):\n",
    "# queryDayData <- function(table,columns, dateCol){\n",
    "#   getTable(table, columns, paste('time(',dateCol,') >= \\'08:00:00\\' AND ', 'time(',dateCol,') < \\'20:00:00\\''))\n",
    "# }\n",
    "# \n",
    "# dayDemo <- queryDayData('wearable_data', 'Timestamp_Local','Timestamp_Local')\n",
    "\n",
    "# getNightData<- function(table, dateCol){\n",
    "#   return(table[hour(eval(dateCol)) < 8 | hour(eval(dateCol)) >= 20])\n",
    "# }\n",
    "# \n",
    "# nightDemo <- getNightData(TB,quote(Date))\n",
    "\n",
    "#Rewrite above daytime function for .csv files:\n",
    "\n",
    "queryDayData <- function(table){\n",
    "  library(dplyr)\n",
    "  table$Timestamp_Local <- fastPOSIXct(table$Timestamp_Local)\n",
    "  return(table %>% \n",
    "           filter( hour(table$Timestamp_Local) >=8 & hour(table$Timestamp_Local) < 20))\n",
    "    \n",
    "}\n",
    "\n",
    "dayDemo = queryDayData(TB)\n",
    "\n",
    "getNightData <- function(table){\n",
    "  library(dplyr)\n",
    "  table$Timestamp_Local <- fastPOSIXct(table$Timestamp_Local)\n",
    "  return(table %>% \n",
    "           filter( hour(table$Timestamp_Local) < 8 | hour(table$Timestamp_Local) >= 20))\n",
    "  \n",
    "}\n",
    "\n",
    "nightDemo = getNightData(TB)\n",
    "\n",
    "##############\n",
    "\n",
    "############\n",
    "# before using the below functions, make sure that the columns you use are of numeric type. You can do so by doing:\n",
    "\n",
    "dayDemo$Heart_Rate <- as.numeric(dayDemo$Heart_Rate)\n",
    "\n",
    "nightDemo$Heart_Rate <- as.numeric(nightDemo$Heart_Rate)\n",
    "\n",
    "if (is_IBI){\n",
    "  dayDemo$IBI<- as.numeric(dayDemo$IBI)\n",
    "  \n",
    "  nightDemo$IBI <- as.numeric(nightDemo$IBI)\n",
    "}\n",
    "\n",
    "############\n",
    "# a function that categorizes a feature to the corresponding quantile\n",
    "# assumption here is that if there's at most one value that crosses multiple quantiles\n",
    "# getQuantile<- function(table, column,newColName, rangeStart, rangeEnd, rangeStep){\n",
    "#   vec <- table[,eval(column)]\n",
    "#   #print(vec)\n",
    "#   quantiles<- quantile(vec, na.rm = TRUE, probs = seq(rangeStart, rangeEnd, by = rangeStep))\n",
    "#   \n",
    "#   #quantiles <-quantile(vec, na.rm = TRUE, probs = seq(rangeStart, rangeEnd, by = rangeStep))\n",
    "#   \n",
    "#   checkPt <- which(table(quantiles) > 1)\n",
    "#   for (i in (2:len)){\n",
    "#     if(quantiles[i]== quantiles[checkPt])\n",
    "#     {\n",
    "#       quantiles[i] = quantiles[checkPt]+runif(1, quantiles[i-1], quantiles[len]/(len*len))\n",
    "#     }\n",
    "#   }\n",
    "#   #cbind(table, findInterval(vec, quantiles))\n",
    "#   return (findInterval(vec, quantiles))\n",
    "#   \n",
    "# }\n",
    "\n",
    "rangeStep = 0.2\n",
    "vec <- TB[,'Heart_Rate']\n",
    "\n",
    "if (is_IBI){\n",
    "  vec <- TB[,'IBI']\n",
    "}\n",
    "\n",
    "quantiles <- quantile(vec, na.rm = TRUE, probs = seq(0, 1, by = rangeStep))\n",
    "\n",
    "\n",
    "#csv file version of getQuantile():\n",
    "getQuantile <- function(table, rangeStep){\n",
    "  quantiles <- quantile(vec, na.rm = TRUE, probs = seq(0, 1, by = rangeStep))\n",
    "  vec <- as.matrix(vec)\n",
    "  #quantiles <- as.double(quantiles)\n",
    "  return (findInterval(vec, quantiles))\n",
    "}\n",
    "\n",
    "rangeStep = 0.2\n",
    "getQuantile(TB, rangeStep)\n",
    "\n",
    "TB = as.data.table(TB)\n",
    "TB$StDecID = getQuantile(TB, rangeStep)\n",
    "\n",
    "#dummy_wearable = makeNum(dummy_wearable, c('Skin_Temperature_F'))\n",
    "#getQuantile(dummy_wearable, 'Skin_Temperature_F', 'SkinTempID',.1,1.0,.1)\n",
    "\n",
    "######################\n",
    "#create a new list which reflect the sum of the items in a specific window\n",
    "window <- function(table, column, groupKey, winSize, func){\n",
    "  vec <- table[,eval(column)]\n",
    "  keyVec<- table[,eval(groupKey)]\n",
    "  newVec = ave(vec, keyVec, FUN = function(x) rollapply(x, width =winSize, FUN= func, align =\"right\", partial = TRUE))\n",
    "  return (newVec)\n",
    "}\n",
    "\n",
    "TB$stepWindow = window(TB, quote(Steps), quote(Wearable_Account_MD5), 10, sum)\n",
    "\n",
    "######################\n",
    "#get resting information based on $keyColumn\n",
    "restInfo<- function(table, column, keyCol, threshold =10)\n",
    "{\n",
    "  subTable = table[(eval(keyCol))< threshold & !is.na(eval(keyCol))]\n",
    "  return(subTable[,eval(column)])\n",
    "}\n",
    "\n",
    "######################\n",
    "\n",
    "#based on the previous function, we now develop a get resting data function, which will append the resting data to the original table\n",
    "TB$keyWindowValue = window(TB, quote(Steps), quote(Wearable_Account_MD5), 10, sum)\n",
    "TB$restInfo = restInfo(TB, quote(Heart_Rate), quote(keyWindowValue),threshold=10)\n",
    "\n",
    "######################\n",
    "#get a subtable of high activity level according to self-defined standard\n",
    "\n",
    "highActivityTable<- function(table, StandardColumn, decile){\n",
    "    subTable <- table[(eval(StandardColumn)) >= decile & !is.na(eval(StandardColumn))]\n",
    "    return (subTable)\n",
    "}\n",
    "\n",
    "HR_highActivityTable = highActivityTable(TB, quote(StDecID),5)\n",
    "\n",
    "######################\n",
    "#get a subtable of high activity level according to self-defined standard\n",
    "#remember to numerize required columns\n",
    "lowActivityTable<- function(table, StandardColumn, decile){\n",
    "  subTable <- table[(eval(StandardColumn)) <= decile & !is.na(eval(StandardColumn))]\n",
    "  return (subTable)\n",
    "}\n",
    "\n",
    "HR_lowActivityTable = lowActivityTable(TB, quote(StDecID),3)\n",
    "\n",
    "#If IBI variable, then change table labels due to fact that IBI has inverted relationship\n",
    "#with activity (i.e., is inverse of HR, which has direct relationship with activity level):\n",
    "\n",
    "if (is_IBI){\n",
    "  IBI_highActivityTable = HR_lowActivityTable\n",
    "  IBI_lowActivityTable = HR_highActivityTable\n",
    "}\n",
    "\n",
    "#Get final resting HR data (night and low activity):\n",
    "\n",
    "all_resting_HR = getNightData(lowActivityTable(TB,quote(StDecID),3))\n",
    "\n",
    "#Generate final summarized per ID resting HR:\n",
    "\n",
    "final_resting_HR = tapply(all_resting_HR$Heart_Rate, all_resting_HR$Wearable_Account_MD5, mean, na.rm = TRUE) \n",
    "\n",
    "#Create final dataframe:\n",
    "final_resting_HR = as.data.frame(final_resting_HR)\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
